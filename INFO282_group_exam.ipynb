{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdce5f",
   "metadata": {},
   "source": [
    "# INFO284 - Group Exam 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9568111",
   "metadata": {},
   "source": [
    "## 1.    Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240251f9",
   "metadata": {},
   "source": [
    "## 2.    Task I: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea4b63",
   "metadata": {},
   "source": [
    "### 2.1 Configutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef201766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "668e8cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>981e465b-d3ba-4632-9c60-25051efac38a</td>\n",
       "      <td>5</td>\n",
       "      <td>It's good</td>\n",
       "      <td>11/22/2025 1:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>964d3555-9429-4c20-8127-ce3c71ce9273</td>\n",
       "      <td>5</td>\n",
       "      <td>WhatsApp not working well always shows offline...</td>\n",
       "      <td>11/24/2025 20:03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6c28859f-1554-4ca1-9aa8-9d66f204be0a</td>\n",
       "      <td>5</td>\n",
       "      <td>Oppo not corresponding, share with me the offi...</td>\n",
       "      <td>11/25/2025 6:26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a7efafc3-5871-4020-a398-9cc12cb4072a</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent app, great communication super conne...</td>\n",
       "      <td>11/25/2025 18:09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de142b31-a5ad-446f-b7c8-51b264728478</td>\n",
       "      <td>4</td>\n",
       "      <td>simply the ɓest for chat and calls.i love it</td>\n",
       "      <td>11/24/2025 1:10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id  rating  \\\n",
       "0  981e465b-d3ba-4632-9c60-25051efac38a       5   \n",
       "1  964d3555-9429-4c20-8127-ce3c71ce9273       5   \n",
       "2  6c28859f-1554-4ca1-9aa8-9d66f204be0a       5   \n",
       "3  a7efafc3-5871-4020-a398-9cc12cb4072a       5   \n",
       "4  de142b31-a5ad-446f-b7c8-51b264728478       4   \n",
       "\n",
       "                                         review_text       review_date  \\\n",
       "0                                          It's good   11/22/2025 1:19   \n",
       "1  WhatsApp not working well always shows offline...  11/24/2025 20:03   \n",
       "2  Oppo not corresponding, share with me the offi...   11/25/2025 6:26   \n",
       "3  Excellent app, great communication super conne...  11/25/2025 18:09   \n",
       "4       simply the ɓest for chat and calls.i love it   11/24/2025 1:10   \n",
       "\n",
       "   helpful  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our data\n",
    "df = pd.read_csv(\"reviews.csv\")\n",
    "\n",
    "# Check first few rows to see if everything is loaded correctly and to get an idea of the structure of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddaf2bc",
   "metadata": {},
   "source": [
    "In this dataset, we have the following 5 columns: review_id, rating, review_text, review_date and helpful. These column names are intuitive, so we keep them. The dataset seems to be reviews of the Whatsapp mobile app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bd72a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6210, 5)\n",
      "Duplicate rows: 0\n",
      "Duplicate review_id: 0\n",
      "Duplicate review_text: 384\n",
      "\n",
      "Missing values per column:\n",
      "review_id      0\n",
      "rating         0\n",
      "review_text    0\n",
      "review_date    0\n",
      "helpful        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Quick overview of the dataset before preprocessing and EDA\n",
    "\n",
    "# Dataset size\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Duplicates\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())\n",
    "print(\"Duplicate review_id:\", df.duplicated(subset=[\"review_id\"]).sum())\n",
    "print(\"Duplicate review_text:\", df.duplicated(subset=[\"review_text\"]).sum())\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067493f3",
   "metadata": {},
   "source": [
    "We see there are 6210 rows across the 5 columns, no missing values and practically no duplicates. Although 384 duplicates appear in review_text, which amount to about 6,2% of the observations, it is reasonable to assume that this is a pure coincidence as many reviews in the dataset are short. Even if some of them are true duplicates, we regard the percentage to be too minisclue to have practical implications for our purposes. Due to this, as well as there not being any missing values, we do not need to keep any adjustments in mind during preprocessing, and can simply continue our work straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21250b",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d4a158",
   "metadata": {},
   "source": [
    "We split the dataset into training, validation, and test sets using stratified random sampling to preserve the distribution of rating classes across all subsets. A random split was chosen because the reviews represent independent observations without temporal dependency, making time-based splitting unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c96b1",
   "metadata": {},
   "source": [
    "A fixed split was preferred over cross-validation to maintain methodological consistency across all four models, including the neural network. Although cross-validation can yield a more robust estimate of performance, it requires repeated model training and significantly increases computational cost, particularly for neural networks, which we will be using later. The chosen approach therefore provides a balanced trade-off between reliability, computational feasibility, and fair model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73b800f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4347\n",
      "Validation size: 931\n",
      "Test size: 932\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "split_df_copy = df[[\"review_text\", \"review_date\", \"helpful\"]]\n",
    "y = df[\"rating\"]\n",
    "\n",
    "# First split: Train (70%) and Temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    split_df_copy, y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Second split: Validation (15%) and Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Print sizes\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Validation size:\", X_val.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a467f",
   "metadata": {},
   "source": [
    "We keep the raw input features review_text and helpful from the original dataframe, and we also create a small set of engineered features. From review_date, we extract month, day_of_week, and hour to capture when reviews are posted, and we compute review_length as the number of words in review_text. The add_features function adds these engineered columns separately to the train, validation, and test splits, and we then keep only the final feature set used for modeling: review_text, helpful, month, day_of_week, hour, and review_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ce619a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4347, 6) (931, 6) (932, 6)\n"
     ]
    }
   ],
   "source": [
    "def add_features(split_df):\n",
    "    split_df_copy = split_df.copy()    # Make a copy so we don't change the original split\n",
    "\n",
    "    # Convert date text to datetime\n",
    "    split_df_copy[\"review_date\"] = pd.to_datetime(split_df_copy[\"review_date\"], errors=\"coerce\")    # errors=\"coerce\" will set invalid parsing to NaT (Not a Time)\n",
    "\n",
    "    # Time features\n",
    "    split_df_copy[\"month\"] = split_df_copy[\"review_date\"].dt.month\n",
    "    split_df_copy[\"day_of_week\"] = split_df_copy[\"review_date\"].dt.dayofweek\n",
    "    split_df_copy[\"hour\"] = split_df_copy[\"review_date\"].dt.hour\n",
    "\n",
    "    # Review length (number of words)\n",
    "    text = split_df_copy[\"review_text\"].fillna(\"\")   # Replace missing text with empty string\n",
    "    words = text.str.split()                         # Split each review into a list of words\n",
    "    split_df_copy[\"review_length\"] = words.str.len() # Count words in each list\n",
    "\n",
    "\n",
    "    return split_df_copy\n",
    "\n",
    "# Add features to each dataset split\n",
    "X_train = add_features(X_train)\n",
    "X_val = add_features(X_val)\n",
    "X_test = add_features(X_test)\n",
    "\n",
    "# Columns we want the models to use\n",
    "cols = [\"review_text\", \"helpful\", \"month\", \"day_of_week\", \"hour\", \"review_length\"]\n",
    "X_train = X_train[cols]\n",
    "X_val = X_val[cols]\n",
    "X_test = X_test[cols]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87847a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rating distribution:\n",
      " rating\n",
      "1    0.254658\n",
      "2    0.075224\n",
      "3    0.081896\n",
      "4    0.101679\n",
      "5    0.486542\n",
      "Name: proportion, dtype: float64\n",
      "Val rating distribution:\n",
      " rating\n",
      "1    0.254565\n",
      "2    0.075188\n",
      "3    0.081633\n",
      "4    0.102041\n",
      "5    0.486574\n",
      "Name: proportion, dtype: float64\n",
      "Test rating distribution:\n",
      " rating\n",
      "1    0.255365\n",
      "2    0.075107\n",
      "3    0.081545\n",
      "4    0.101931\n",
      "5    0.486052\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that stratification worked\n",
    "print(\"Train rating distribution:\\n\", y_train.value_counts(normalize=True).sort_index())\n",
    "print(\"Val rating distribution:\\n\", y_val.value_counts(normalize=True).sort_index())\n",
    "print(\"Test rating distribution:\\n\", y_test.value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8692881f",
   "metadata": {},
   "source": [
    "The sanity check looks good. The class proportions are almost identical across train, validation, and test, which confirms that stratified sampling preserved the rating distribution as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8316b979",
   "metadata": {},
   "source": [
    "### 2.3 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169a7f4",
   "metadata": {},
   "source": [
    "We start our exploratory data analysis (EDA) with a statistical summary of the dataframe we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e4e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical summary of numeric features in training data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>missing_percent</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>4347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.74</td>\n",
       "      <td>3778.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>3795.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <td>3795.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>3795.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.44</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_length</th>\n",
       "      <td>4347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.32</td>\n",
       "      <td>19.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count  missing_percent   mean      std   min   25%   50%  \\\n",
       "helpful        4347.0              0.0  60.74  3778.50   0.0   0.0   0.0   \n",
       "month          3795.0             12.7  11.00     0.00  11.0  11.0  11.0   \n",
       "day_of_week    3795.0             12.7   2.84     2.27   0.0   1.0   2.0   \n",
       "hour           3795.0             12.7  13.44     6.98   0.0   9.0  15.0   \n",
       "review_length  4347.0              0.0  15.32    19.42   1.0   3.0   7.0   \n",
       "\n",
       "                75%       max  \n",
       "helpful         0.0  248962.0  \n",
       "month          11.0      11.0  \n",
       "day_of_week     5.0       6.0  \n",
       "hour           20.0      23.0  \n",
       "review_length  19.0     105.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only want to summarize the numeric features, so we select those columns\n",
    "numeric_cols = [\"helpful\", \"month\", \"day_of_week\", \"hour\", \"review_length\"]\n",
    "\n",
    "# Basic summary statistics (count, mean, std, min, quartiles, max)\n",
    "stats_table = X_train[numeric_cols].describe().T\n",
    "\n",
    "# Add percent of missing values for each feature\n",
    "stats_table[\"missing_percent\"] = (X_train[numeric_cols].isna().mean() * 100)\n",
    "\n",
    "# Keep the columns we care about and round to 2 decimals\n",
    "stats_table = stats_table[[\"count\", \"missing_percent\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"]].round(2)\n",
    "\n",
    "stats_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63588a",
   "metadata": {},
   "source": [
    "Se Chat for hvordan vi tyder dette og hva vi skal gjøre med dette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808acee",
   "metadata": {},
   "source": [
    "### 2.4 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5f065",
   "metadata": {},
   "source": [
    "### 2.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4ddc3",
   "metadata": {},
   "source": [
    "### 2.6 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c4a1f1",
   "metadata": {},
   "source": [
    "## 3.    Task II: Convolutional Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0659a",
   "metadata": {},
   "source": [
    "### 3.X Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637201d",
   "metadata": {},
   "source": [
    "### 3.X Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788f1cc",
   "metadata": {},
   "source": [
    "### 3.X Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d0abd",
   "metadata": {},
   "source": [
    "### 3.X Model Choice and Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899b416",
   "metadata": {},
   "source": [
    "### 3.X Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58196a10",
   "metadata": {},
   "source": [
    "### 3.X Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0101c0",
   "metadata": {},
   "source": [
    "### 3.X Testing on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a66b6",
   "metadata": {},
   "source": [
    "### 3.X Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d4efb",
   "metadata": {},
   "source": [
    "## 4. Final Summary and Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104205a",
   "metadata": {},
   "source": [
    "## 5. References & Tools Used"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
